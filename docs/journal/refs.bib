@article{seymour2011history,
  title = {History of search engines},
  author = {Seymour, Tom and Frantsvog, Dean and Kumar, Satheesh},
  journal = {International Journal of Management \& Information Systems (IJMIS)},
  volume = {15},
  number = {4},
  pages = {47--58},
  year = {2011},
}

@article{brin1998anatomy,
  title = {The anatomy of a large-scale hypertextual web search engine},
  author = {Brin, Sergey and Page, Lawrence},
  year = {1998},
}

@article{multithreadedtextsearch,
  title = {On Multi-Thread Crawler Optimization for Scalable Text Searching},
  author = {Sun, Guang and Xiang, Huanxing and Li, Shuanghu},
  year = {2019},
}

@article{Pramudita_2020,
  year = {2020},
  month = {jul},
  publisher = {IOP Publishing},
  volume = {1569},
  number = {2},
  pages = {022077},
  author = {Y D Pramudita and D R Anamisa and S S Putro and M A Rahmawanto},
  title = {Extraction System Web Content Sports New Based On Web Crawler Multi
           Thread},
  journal = {Journal of Physics: Conference Series},
  abstract = {Web crawlers are programs that are used by search engines to
              collect necessary information from the internet automatically
              according to the rules set by the user. With so much information
              about sports news on the internet, it takes web crawlers with
              incredible speed in the process of crawling. There are several
              previous studies that discussed the process of extracting
              information in a web document that needs to be considered both in
              terms of both aspects, including in terms of the structure of the
              web page and the length of time needed. Therefore, in this research
              the web crawler application was developed by applying a
              multi-thread approach. This multi-thread approach to research is
              used to produce web crawlers that are faster in the process of
              crawling sports news by involving news sources more than one
              address at a time. In addition to the multi-thread approach,
              adjusting the structure of the website pages is also done to ensure
              the information to be extracted by web crawling. From the results
              of the multi-thread implementation test on the crawling process,
              this study has been able to increase speed compared to the
              single-thread method of 122.95 seconds. But the results of web
              update detection, have resulted in a speed that decreased by 6.27
              seconds in the crawling process with unequal data and the speed on
              the crawling process has also decreased by 24.76 seconds on server
              1 and by 23.92 seconds on server 2.},
}

@article{RustPerformance,
  author = {Lin, Yi and Blackburn, Stephen M. and Hosking, Antony L. and Norrish
            , Michael},
  title = {Rust as a language for high performance GC implementation},
  year = {2016},
  issue_date = {November 2016},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {51},
  number = {11},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/3241624.2926707},
  doi = {10.1145/3241624.2926707},
  abstract = {High performance garbage collectors build upon
              performance-critical low-level code, typically exhibit multiple
              levels of concurrency, and are prone to subtle bugs. Implementing,
              debugging and maintaining such collectors can therefore be
              extremely challenging. The choice of implementation language is a
              crucial consideration when building a collector. Typically, the
              drive for performance and the need for efficient support of
              low-level memory operations leads to the use of low-level languages
              like C or C++, which offer little by way of safety and software
              engineering benefits. This risks undermining the robustness and
              flexibility of the collector design. Rust's ownership model,
              lifetime specification, and reference borrowing deliver safety
              guarantees through a powerful static checker with little runtime
              overhead. These features make Rust a compelling candidate for a
              collector implementation language, but they come with restrictions
              that threaten expressiveness and efficiency. We describe our
              experience implementing an Immix garbage collector in Rust and C.
              We discuss the benefits of Rust, the obstacles encountered, and how
              we overcame them. We show that our Immix implementation has almost
              identical performance on micro benchmarks, compared to its
              implementation in C, and outperforms the popular BDW collector on
              the gcbench micro benchmark. We find that Rust's safety features do
              not create significant barriers to implementing a high performance
              collector. Though memory managers are usually considered low-level,
              our high performance implementation relies on very little unsafe
              code, with the vast majority of the implementation benefiting from
              Rust's safety. We see our experience as a compelling
              proof-of-concept of Rust as an implementation language for high
              performance garbage collection.},
  journal = {SIGPLAN Not.},
  month = {jun},
  pages = {89â€“98},
  numpages = {10},
  keywords = {memory management, garbage collection, Rust},
}

@article{cho1998efficient,
  title = {Efficient crawling through URL ordering},
  author = {Cho, Junghoo and Garcia-Molina, Hector and Page, Lawrence},
  year = {1998},
}

@book{cormen2009introduction,
  title = {Introduction to algorithms},
  author = {Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and
            Stein, Clifford},
  year = {2009},
  publisher = {MIT press},
}

@book{operatingsystemconcept,
  title = {Operating System Concepts},
  author = {Abraham Silberchschatz, Peter Baer Galvin, Greg Gagne},
  year = {2018},
  publisher = {Willey},
}

@book{rustbook,
  title = {The Rust Programming Language},
  author = {Steve Klabnik, Carol Nichols},
  year = {2018},
  isbn = {1-59327-828-4},
  publisher = {William Pollock},
}

 %23
@article{lazuardithesis,
  title = {PERANCANGAN ARSITEKTUR SEARCH ENGINE DENGAN MENGINTEGRASIKAN WEB
           CRAWLER, ALGORITMA PAGE RANKING, DAN DOCUMENT RANKING},
  author = {Lazuardy Khatulistiwa},
  year = {2023},
}

@article{fathanthesis,
  title = {PERANCANGAN CRAWLER SEBAGAI PENDUKUNG PADA SEARCH ENGINE},
  author = {Muhammad Farthan Qorriba},
  year = {2021},
}
